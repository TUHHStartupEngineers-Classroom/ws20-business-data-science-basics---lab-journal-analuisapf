---
title: "Journal (reproducible report)"
author: "Ana Luísa Procópio Florêncio"
date: "2020-11-05"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: true
    toc_depth: 3
    #code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

**IMPORTANT:** You can delete everything in here and start fresh. You might want to start by not deleting anything above this line until you know what that stuff is doing.

This is an `.Rmd` file. It is plain text with special features. Any time you write just like this, it will be compiled to normal text in the website. If you put a \# in front of your text, it will create a top level-header.

# My first post

Last compiled: `r Sys.Date()`

Notice that whatever you define as a top level header, automatically gets put into the table of contents bar on the left. 

## Second level header

You can add more headers by adding more hashtags. These won't be put into the table of contents

### third level header

Here's an even lower level header

# My second post (note the order)

Last compiled: `r Sys.Date()`

I'm writing this tutorial going from the top down. And, this is how it will be printed. So, notice the second post is second in the list. If you want your most recent post to be at the top, then make a new post starting at the top. If you want the oldest first, do, then keep adding to the bottom

# Adding R stuff

So far this is just a blog where you can write in plain text and serve your writing to a webpage. One of the main purposes of this lab journal is to record your progress learning R. The reason I am asking you to use this process is because you can both make a website, and a lab journal, and learn R all in R-studio. This makes everything really convenient and in the same place.

So, let's say you are learning how to make a histogram in R. For example, maybe you want to sample 100 numbers from a normal distribution with mean = 0, and standard deviation = 1, and then you want to plot a histogram. You can do this right here by using an r code block, like this:

```{r}
samples <- rnorm(100, mean=0, sd=1)
hist(samples)
```

When you knit this R Markdown document, you will see that the histogram is printed to the page, along with the R code. This document can be set up to hide the R code in the webpage, just delete the comment (hashtag) from the cold folding option in the yaml header up top. For purposes of letting yourself see the code, and me see the code, best to keep it the way that it is. You'll learn that all of these things and more can be customized in each R code block.

Hi update

```{r plot, fig.width=10, fig.height=7}




sales_by_state %>%
  
  # Setup canvas with the columns year (x-axis) and sales (y-axis)
  ggplot(aes(x = state, y = sales)) +
  
  # Geometries
  geom_col(fill = "#2DC6D6") + # Use geom_col for a bar plot
  geom_label(aes(label = sales_text)) + # Adding labels to the bars
  geom_smooth(method = "lm", se = FALSE) + # Adding a trendline
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  
  # Formatting
  # scale_y_continuous(labels = scales::dollar) + # Change the y-axis. 
  # Again, we have to adjust it for euro values
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".", 
                                                    decimal.mark = ",", 
                                                    prefix = "", 
                                                    suffix = " €")) +
  labs(
    title    = "Revenue by state",
    subtitle = "Upward Trend",
    x = "", # Override defaults for x and y
    y = "Revenue"
  )

# Step 2 - Visualize

sales_by_state_year %>%
  
  # Set up x, y, fill
  ggplot(aes(x = year, y = sales, fill = state)) +
  
  # Geometries
  geom_col() + # Run up to here to get a stacked bar plot
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  
  # Facet
  facet_wrap(~ state) +
  
  # Formatting
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".", 
                                                    decimal.mark = ",", 
                                                    prefix = "", 
                                                    suffix = " €")) +
  labs(
    title = "Revenue by year and state",
    subtitle = "Each product category has an upward trend",
    fill = "Main category" # Changes the legend name
  )

```

```{r}
library(httr)
library(glue)

token <- Sys.getenv("apikey")


resp <- GET(glue("http://api.openweathermap.org/data/2.5/weather?q=London,uk&APPID={token}"))

resp

rawToChar(resp$content)

```

Bike Challenge
```{r, echo = FALSE}

# WEBSCRAPING ----

# 1.0 LIBRARIES ----
# rm(list=ls())
# gc()

library(tidyverse) # Main Package - Loads dplyr, purrr, etc.
library(rvest)     # HTML Hacking & Web Scraping
library(xopen)     # Quickly opening URLs
library(jsonlite)  # converts JSON files to R objects
library(glue)      # concatenate strings
library(stringi)   # character string/text processing
library(future)
library(furrr) 
# 1.1 COLLECT PRODUCT FAMILIES ----

rose_url_home          <- "https://www.rosebikes.de/fahrr%C3%A4der/mtb"
# xopen(rose_url_home) # Open links directly from RStudio to inspect them

# Read in the HTML for the entire webpage
rose_html_home         <- read_html(rose_url_home)

# Web scrape the ids for the families
rose_bike_family_tbl <- rose_html_home %>%
  
  # Get the nodes for the families ...
  html_nodes(css = ".catalog-navigation__link") %>%
  # ...and extract the information of the id attribute
  html_attr('href') %>%
  
  # Remove the product families Gear and Outlet and Woman
  # (because the female bikes are also listed with the others)
  discard(.p = ~stringr::str_detect(.x,"All|Trail")) %>%
  
  # Convert vector to tibble
  enframe(name = "position", value = "family_class") %>%
  
  # Add a hashtag so we can get nodes of the categories by id (#)
  mutate(
    family_id = str_glue("#{family_class}")
  )


# 1.2 COLLECT PRODUCT CATEGORIES ----

# # Combine all Ids to one string so that we will get all nodes at once
# # (seperated by the OR operator ",")
rose_family_id_css <- rose_bike_family_tbl %>%
  pull(family_id) %>%
  stringr::str_c(collapse = ", ")


# Extract the urls from the href attribute
rose_bike_category_tbl <- data.frame(rose_bike_family_tbl[-1,1:2]) %>%
  # enframe(name = "position", value = "subdirectory") # %>%
  
  # Add the domain, because we will get only the subdirectories
  mutate(
    url = glue("https://www.rosebikes.de{family_class}")
  ) %>%
  dplyr::select(url) %>% 
  # Some categories are listed multiple times.
  # We only need unique values
  distinct(url)


# 2.0 COLLECT BIKE DATA ----

# 2.1 Get URL for each bike of the Product categories

# select first bike category url
rose_bike_category_url <- rose_bike_category_tbl$url[1]

# Alternatives for selecting values
# bike_category_url <- bike_category_tbl %$% url %>% .[1]
# bike_category_url <- bike_category_tbl %>% pull(url) %>% .[1]
# bike_category_url <- deframe(bike_category_tbl[1,])
# bike_category_url <- bike_category_tbl %>% first %>% first

# Get the URLs for the bikes of the first category
rose_html_bike_category  <- read_html(rose_bike_category_url)
rose_bike_url_tbl        <- rose_html_bike_category %>%
  
  # Get the 'a' nodes, which are hierarchally underneath 
  # the class productTile__contentWrapper
  html_nodes(css = ".row .align-middle > a") %>%
  html_attr("href") %>%
  
  # Convert vector to tibble
  enframe(name = "position", value = "url") %>%
  mutate(
    url = glue("https://www.rosebikes.de{url}")
  )



# 2.1.3 Get even more data from JSON files
rose_bike_json_tbl1  <- rose_html_bike_category %>%  
  html_nodes(css = '.catalog-category-bikes__price-title') %>%
  html_text() %>%
  str_remove("ab") %>%
  enframe(name = "position", value = "price") 
 

rose_bike_json_tbl  <- rose_html_bike_category %>%
  html_nodes(css = '.catalog-category-bikes__title') %>%
  html_text() %>% 
  enframe(name = "position", value = "name") %>%
  left_join(rose_bike_json_tbl1) %>%
  left_join(rose_bike_url_tbl)
  

# 2.2 Wrap it into a function ----
rose_get_bike_data <- function(url) {
  
  rose_html_bike_category <- read_html(url)
  
  # Get the URLs
  rose_bike_url_tbl  <- rose_html_bike_category %>%
    html_nodes(css = ".row .align-middle > a") %>%
    html_attr("href") %>%
    enframe(name = "position", value = "url") %>%
    mutate(
    url = glue("https://www.rosebikes.de{url}")
  )
 
  # Get JSON data
  rose_bike_json_tbl1  <- rose_html_bike_category %>%  
    html_nodes(css = '.catalog-category-bikes__price-title') %>%
    html_text() %>%
    str_remove("ab") %>%
    enframe(name = "position", value = "price") 
  
  
  rose_bike_json_tbl2  <- rose_html_bike_category %>%
    html_nodes(css = '.catalog-category-bikes__title') %>%
    html_text() %>% 
    enframe(name = "position", value = "name") %>%
    left_join(rose_bike_json_tbl1) %>%
    left_join(rose_bike_url_tbl)
}


# 2.3.1a Map the function against all urls

# Extract the urls as a character vector
rose_bike_category_url_vec <- rose_bike_category_tbl %>% 
  pull(url)


# Run the function with every url as an argument
rose_bike_data_lst <- purrr::map(rose_bike_category_url_vec, rose_get_bike_data)

# Merge the list into a tibble
rose_bike_data_tbl <- bind_rows(rose_bike_data_lst)
saveRDS(rose_bike_data_tbl, "rose_bike_data_tbl.rds")

rose_bike_data_tbl$position <- NULL

rose_bike_data_tbl1 <- rose_bike_data_tbl %>%
  mutate(price =  price %>% str_remove_all("€|\\.|\\,") %>% str_trim() %>% as.numeric)

rose_bike_data_tbl1



```

For the challenge in Data Wrangling I used the reduced Data set provided by Joschka:

```{r, echo = FALSE}
library(vroom)
# Tidyverse
library(tidyverse)


# Data Table
library(data.table)
#install.packages("tictoc")
# Counter
library(tictoc)
col_types_patent <- list(
  id = col_character(),
  date = col_date("%Y-%m-%d"),
  num_claims = col_double()
)

patent_tbl <- vroom(
  file       = "patent.tsv", 
  delim      = "\t", 
  col_types  = col_types_patent,
  na         = c("", "NA", "NULL")
)

setDT(patent_tbl)

col_types_assignee <- list(
  id = col_character(),
  type = col_double(),
  organization = col_character()
)

assignee_tbl <- vroom(
  file       = "assignee.tsv", 
  delim      = "\t", 
  col_types  = col_types_assignee,
  na         = c("", "NA", "NULL")
)

setDT(assignee_tbl)

col_types_patent_assignee <- list(
  patent_id = col_character(),
  assignee_id = col_character()
)

patent_assignee_tbl <- vroom(
  file       = "patent_assignee.tsv", 
  delim      = "\t", 
  col_types  = col_types_patent_assignee,
  na         = c("", "NA", "NULL")
)

setDT(patent_assignee_tbl)

col_types_uspc <- list(
  patent_id = col_character(),
  mainclass_id = col_character(),
  sequence = col_double()
)

patent_uspc <- vroom(
  file       = "uspc.tsv", 
  delim      = "\t", 
  col_types  = col_types_uspc,
  na         = c("", "NA", "NULL")
)

setDT(patent_uspc)

```

1: Patent Dominance:
What US company / corporation has the most patents? List the 10 US companies with the most assigned/granted patents.

```{r, echo = FALSE}

# 1: Patent Dominance: ----
# What US company / corporation has the most patents? List the 10 US companies with the most assigned/granted patents.



combined_data_ass_patass <- merge(x = assignee_tbl, y = patent_assignee_tbl, 
                       by.x = "id", by.y = "assignee_id", 
                       all.x = TRUE, 
                       all.y = TRUE)


patent_dominance <- combined_data_ass_patass[!is.na(organization), .N, by = organization][order(-N),][1:10]


patent_dominance
```

2: Recent patent acitivity:
What US company had the most patents granted in 2019? List the top 10 companies with the most new granted patents for 2019.
Adaptation: Month of May

```{r, echo = FALSE}
# 2: Recent patent acitivity: ----
# What US company had the most patents granted in 2019? List the top 10 companies with the most new granted patents for 2019.
# Adaptation: Month of May


combined_data_ass_patass_pat <- merge(x = combined_data_ass_patass, y = patent_tbl, 
                                  by.x = "patent_id", by.y = "id",
                                  all.x = TRUE, 
                                  all.y = TRUE)


#patent_assignee_tbl[(patent_id %like% "8636251")]


patent_activity <- combined_data_ass_patass_pat[(!is.na(organization) & lubridate::month(date, label = T, abbr = F) == "Mai"), .N, by = organization][order(-N),][1:10]


patent_activity
```


3: Innovation in Tech:
What is the most innovative tech sector? For the top 10 companies (worldwide) with the most patents, what are the top 5 USPTO tech main classes?
```{r, echo = FALSE}
#3: Innovation in Tech: ----
# What is the most innovative tech sector? For the top 10 companies (worldwide) with the most patents, what are the top 5 USPTO tech main classes?


combined_data_ass_patass_uspc <- merge(x = combined_data_ass_patass, y = patent_uspc, 
                                      by = "patent_id",
                                      all.x = TRUE, 
                                      all.y = TRUE)



innovation_in_tech <- combined_data_ass_patass_uspc[!is.na(id), .N, by = organization][order(-N),][1:10]


innovation_in_tech

```

COVID-19 confirmed cases worldwide

```{r, echo = FALSE}
library(tidyverse)
library(lubridate)
#install.packages("ggrepel")
library(ggrepel)
covid_data_tbl <- read_csv("https://opendata.ecdc.europa.eu/covid19/casedistribution/csv")

covid_data_1_tbl <- covid_data_tbl %>%
  select(continentExp,dateRep, cases_weekly) %>%
  
  group_by(continentExp, lubridate::month(dateRep, label = T, abbr = F)) %>%
  summarise(cases = sum(cases_weekly)) %>%
  ungroup() %>%
  
  rename(month = "lubridate::month(dateRep, label = T, abbr = F)") %>%
  
  group_by(continentExp) %>%
  mutate(cum_cases = cumsum(cases)) %>%
  ungroup() %>%
  
  mutate(continentExp = fct_reorder2(continentExp, month, cum_cases))


covid_data_1_tbl %>%
  mutate(continentExp_num = as.numeric(continentExp)) %>%
  arrange(continentExp)

pacman::p_load("ggplot2")
# Put the aes color mapping here, to apply it to geom_line and geom_point
ggplot() +
  geom_line(data=covid_data_1_tbl, aes(x=month, y=cum_cases,group=continentExp, color = continentExp))+
  
  theme_light() +
  
  theme(
    axis.text.x = element_text(
      angle = 45,
      hjust = 1
    )
  ) +
  
  labs(
    title = "COVID-19 confirmed cases worldwide",
    subtitle = "As of April 2020, Europe had more cases than America",
    x = "Year 2020",
    y = "Cumulative Cases",
    fill = "",
    caption = ""
  )

```

Covid-19 Mortality in the World

```{r, echo = FALSE}


# Challenge 2 ----

library(maps)

world <- map_data("world")

covid_data_2_tbl <- covid_data_tbl %>%
  mutate(across(countriesAndTerritories, str_replace_all, "_", " ")) %>%
  mutate(countriesAndTerritories = case_when(
    
    countriesAndTerritories == "United Kingdom" ~ "UK",
    countriesAndTerritories == "United States of America" ~ "United States",
    countriesAndTerritories == "Czechia" ~ "Czech Republic",
    TRUE ~ countriesAndTerritories
    
  )) %>%
  
  
  select(countryterritoryCode,countriesAndTerritories, deaths_weekly, popData2019) %>%
  mutate(mortality = deaths_weekly/popData2019) %>%
  
  group_by(countryterritoryCode) %>%
  summarise(mortality_total = sum(mortality)) %>%
  ungroup() %>%
  
  mutate(mortality_pct = scales::percent(mortality_total, accuracy = 0.0001))


pacman::p_load("tmap", "sp", "spdplyr")
data("World")

World <- as(World, "Spatial")
World@proj4string

World <- World %>%
  left_join(covid_data_2_tbl, by = c("iso_a3"="countryterritoryCode"))



tm_shape(World)+
  tm_polygons("mortality_total", palette="YlOrRd",style="cont", n=10)+
  tm_layout(legend.outside = TRUE) 


```